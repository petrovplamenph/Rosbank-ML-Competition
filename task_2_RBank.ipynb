{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EMO\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model, Model, Sequential\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "%matplotlib  inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EMO\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"df_t_2_\")\n",
    "# Drop some features that were not usefell for the task\n",
    "df.drop(columns=[\"POS_CAT_before\",\"POS_CAT_during\",\"num_trx_during\",\"num_trx_before\"], inplace=True)\n",
    "df_only_pos = df[df[\"flags\"]==1]\n",
    "y = df_only_pos[\"sums\"]\n",
    "X = df_only_pos\n",
    "X.drop(columns=[\"sums\",\"flags\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop  outliers\n",
    "print(X.shape[0]-X[y<1000000].shape[0])\n",
    "X = X[y<1000000]\n",
    "y = y[y<1000000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5) \n",
    "\n",
    "\n",
    "samples_train = X_train.shape[0]\n",
    "samples_test = X_test.shape[0]\n",
    "samples_val  = X_val.shape[0]\n",
    "\n",
    "X_train_nn = X_train\n",
    "X_test_nn = X_test\n",
    "\n",
    "\n",
    "y_train_nn = y_train.reshape(samples_train,1)\n",
    "y_test_nn = y_test.reshape(samples_test,1)\n",
    "y_val = y_val.reshape(samples_val,1)\n",
    "\n",
    "X_val = X_val.as_matrix()\n",
    "X_train_nn=X_train_nn.as_matrix()\n",
    "X_test_nn=X_test_nn.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_clf(clf,X_train, X_test, y_train, y_test):\n",
    "    model = clf.fit(X_train, y_train)\n",
    "    print(\"Baseline\")\n",
    "    print(\"train error\",mean_absolute_error(y_train, model.predict(X_train)))\n",
    "    print(\"test error\",mean_absolute_error(y_test, model.predict(X_test)))\n",
    "    return \n",
    "train_clf(DummyRegressor(), X_train, X_test, y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_2_layers(h_layer_1_nodes, h_layer_2_nodes, A1, A2, l2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(h_layer_1_nodes, input_dim=X_train.shape[1], activation= A1,kernel_regularizer=regularizers.l2(l2)))\n",
    "    model.add(Dense(h_layer_2_nodes, activation=A2 ,kernel_regularizer=regularizers.l2(l2)))\n",
    "    model.add(Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_2_layers(2, 2, \"relu\",\"relu\", 0.05)\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "train_errs = []\n",
    "test_errs = []\n",
    "epoch = 200\n",
    "counter = 0\n",
    "best_err = 1000000000\n",
    "last_epoch = epoch\n",
    "for ep in range(1,epoch):\n",
    "    model.fit(X_train_nn, y_train_nn, epochs=1, batch_size=32, shuffle=True,verbose=0)\n",
    "    test_predictions = model.predict(X_test_nn, batch_size=32, verbose=0)\n",
    "    train_predictions = model.predict(X_train_nn, batch_size=32, verbose=0)\n",
    "    test_err = mean_absolute_error(y_test_nn, test_predictions)\n",
    "    train_err = mean_absolute_error(y_train_nn, train_predictions)\n",
    "    train_errs.append(train_err)\n",
    "    test_errs.append(test_err)\n",
    "    if best_err>test_err:\n",
    "        model.save_weights(\"weights_task_2.h5\")\n",
    "        best_err = test_err\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "    if counter == 20:\n",
    "        last_epoch = (ep+1)\n",
    "        break\n",
    "\n",
    "\n",
    "print(mean_absolute_error(y_train, train_predictions))\n",
    "print(mean_absolute_error(y_test, test_predictions))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(1,last_epoch), train_errs, \"b--\", label=\"train\")\n",
    "ax.plot(range(1,last_epoch), test_errs, \"r--\", label=\"valid\")\n",
    "ax.set(xlabel='epochs', ylabel='MAD',\n",
    "       title='Mean Absolute error(epochs)')\n",
    "\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model error estemate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_flow_model = model_2_layers(2, 2, \"relu\",\"relu\", 0.05)\n",
    "output_flow_model.load_weights(\"weights_task_2.h5\")\n",
    "predictions = output_flow_model.predict(X_val, batch_size=32, verbose=0)\n",
    "err = mean_absolute_error(y_val, predictions)\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"df_task_2_sub\")\n",
    "df.drop(columns=[\"POS_CAT_before\",\"POS_CAT_during\"], inplace=True)\n",
    "\n",
    "X_full_task_2 = df.as_matrix()\n",
    "df = pd.read_pickle(\"df_t1_for_t2\")\n",
    "X_full_task_1 = df.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=X_train.shape[1], activation= \"relu\",kernel_regularizer=regularizers.l2(0.05)))\n",
    "model.add(Dense(2, activation=\"relu\" ,kernel_regularizer=regularizers.l2(0.05)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: P(A)*P(B|A) where:                                                          \n",
    "   P(A) - Probability custumer will countine to use the service                        \n",
    "    \n",
    "   P(B|A) - output via posterminal if the user countinue to use the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_3_layers(h_layer_1_nodes, h_layer_2_nodes, h_layer_3_nodes, A1, A2, A3, l2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(h_layer_1_nodes, input_dim=35, activation= A1,kernel_regularizer=regularizers.l2(l2)))\n",
    "    model.add(Dense(h_layer_2_nodes, activation=A2 ,kernel_regularizer=regularizers.l2(l2)))\n",
    "    model.add(Dense(h_layer_3_nodes, activation=A3,kernel_regularizer=regularizers.l2(l2)))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "probability_model = model_3_layers(14, 34, 7, \"relu\",\"relu\", \"tanh\", 0.0014492103248979129)\n",
    "probability_model.load_weights(\"weights.h5\")\n",
    "output_flow_model = model_2_layers(2, 2, \"relu\",\"relu\", 0.05)\n",
    "output_flow_model.load_weights(\"weights_task_2.h5\")\n",
    "\n",
    "probs = probability_model.predict(X_full_task_1)[:,1]\n",
    "outputs = output_flow_model.predict(X_full_task_2)\n",
    "final_pos_flow = probs*outputs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
